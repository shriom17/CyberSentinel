"""
Real-time dashboard routes for live cybercrime prediction
"""
from flask import Blueprint, request, jsonify
import numpy as np
from datetime import datetime, timedelta
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.real_time_processor import real_time_processor

realtime_bp = Blueprint('realtime', __name__)

@realtime_bp.route('/start-monitoring', methods=['POST'])
def start_real_time_monitoring():
    """Start real-time monitoring and prediction"""
    try:
        if not real_time_processor.is_running:
            real_time_processor.start_processing()
            return jsonify({
                'success': True,
                'message': 'Real-time monitoring started',
                'status': 'active'
            })
        else:
            return jsonify({
                'success': True,
                'message': 'Real-time monitoring already running',
                'status': 'active'
            })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@realtime_bp.route('/stop-monitoring', methods=['POST'])
def stop_real_time_monitoring():
    """Stop real-time monitoring"""
    try:
        if real_time_processor.is_running:
            real_time_processor.stop_processing()
            return jsonify({
                'success': True,
                'message': 'Real-time monitoring stopped',
                'status': 'inactive'
            })
        else:
            return jsonify({
                'success': True,
                'message': 'Real-time monitoring already stopped',
                'status': 'inactive'
            })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@realtime_bp.route('/monitoring-status', methods=['GET'])
def get_monitoring_status():
    """Get current monitoring status"""
    try:
        status = {
            'is_running': real_time_processor.is_running,
            'last_update': real_time_processor.last_update.isoformat(),
            'queue_size': real_time_processor.data_queue.qsize(),
            'subscribers': len(real_time_processor.subscribers),
            'uptime': str(datetime.now() - real_time_processor.last_update) if real_time_processor.is_running else 'Not running'
        }
        
        return jsonify({
            'success': True,
            'status': status
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@realtime_bp.route('/live-predictions', methods=['GET'])
def get_live_predictions():
    """Get current real-time predictions"""
    try:
        predictions = real_time_processor.get_current_predictions()
        
        return jsonify({
            'success': True,
            'predictions': predictions['predictions'],
            'last_update': predictions['last_update'],
            'status': predictions['status'],
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@realtime_bp.route('/live-hotspots', methods=['GET'])
def get_live_hotspots():
    """Get real-time hotspot predictions"""
    try:
        predictions = real_time_processor.get_current_predictions()
        hotspots = predictions['predictions'].get('hotspots', [])
        
        # Enhance with geographical data
        enhanced_hotspots = []
        for hotspot in hotspots:
            enhanced_hotspot = {
                **hotspot,
                'coordinates': get_city_coordinates(hotspot['city']),
                'severity': get_severity_level(hotspot['predicted_incidents']),
                'eta_minutes': estimate_response_time(hotspot['city']),
                'recommended_units': calculate_required_units(hotspot['predicted_incidents'])
            }
            enhanced_hotspots.append(enhanced_hotspot)
        
        return jsonify({
            'success': True,
            'hotspots': enhanced_hotspots,
            'total_count': len(enhanced_hotspots),
            'last_update': predictions['last_update']
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@realtime_bp.route('/live-alerts', methods=['GET'])
def get_live_alerts():
    """Get current active alerts"""
    try:
        # In production, this would query alert management system
        # For now, generate based on current high-risk predictions
        predictions = real_time_processor.get_current_predictions()
        
        alerts = []
        hotspots = predictions['predictions'].get('hotspots', [])
        risk_areas = predictions['predictions'].get('risk_areas', [])
        
        # Generate alerts for high-risk hotspots
        for hotspot in hotspots:
            if hotspot['risk_level'] == 'high':
                alert = {
                    'id': f"HOTSPOT_ALERT_{hotspot['city']}_{datetime.now().strftime('%H%M')}",
                    'type': 'hotspot_prediction',
                    'severity': 'high',
                    'title': f"High Activity Predicted: {hotspot['city']}",
                    'message': f"Predicted {hotspot['predicted_incidents']} incidents in next hour",
                    'location': hotspot['city'],
                    'coordinates': get_city_coordinates(hotspot['city']),
                    'confidence': hotspot['confidence'],
                    'timestamp': datetime.now().isoformat(),
                    'action_required': True,
                    'estimated_impact': hotspot['predicted_incidents'] * 100000  # Estimated financial impact
                }
                alerts.append(alert)
        
        # Generate alerts for risk areas
        for area in risk_areas[:3]:  # Top 3 risk areas
            alert = {
                'id': f"RISK_AREA_{area['area']}_{datetime.now().strftime('%H%M')}",
                'type': 'risk_area',
                'severity': 'medium' if area['risk_score'] < 0.8 else 'high',
                'title': f"Risk Area Identified: {area['area']}",
                'message': f"â‚¹{area['total_amount']:,} involved in {area['incidents']} incidents",
                'location': area['area'],
                'coordinates': area['location'],
                'risk_score': area['risk_score'],
                'timestamp': datetime.now().isoformat(),
                'action_required': area['risk_score'] > 0.8,
                'estimated_impact': area['total_amount']
            }
            alerts.append(alert)
        
        return jsonify({
            'success': True,
            'alerts': alerts,
            'total_count': len(alerts),
            'high_priority_count': len([a for a in alerts if a['severity'] == 'high']),
            'last_update': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@realtime_bp.route('/live-statistics', methods=['GET'])
def get_live_statistics():
    """Get real-time statistics based on actual processing"""
    try:
        predictions = real_time_processor.get_current_predictions()
        
        # Calculate real statistics from processed data
        queue_size = real_time_processor.data_queue.qsize()
        hotspots = predictions['predictions'].get('hotspots', [])
        risk_areas = predictions['predictions'].get('risk_areas', [])
        trends = predictions['predictions'].get('trends', {})
        
        # Calculate totals
        total_predicted_incidents = sum(h['predicted_incidents'] for h in hotspots)
        total_risk_amount = sum(r['total_amount'] for r in risk_areas)
        high_risk_areas = len([r for r in risk_areas if r['risk_score'] > 0.7])
        
        # Calculate prediction accuracy (simulated based on recent performance)
        accuracy = 0.85 + (len(hotspots) * 0.02)  # Higher accuracy with more data
        accuracy = min(accuracy, 0.95)  # Cap at 95%
        
        statistics = {
            'processing_status': 'active' if real_time_processor.is_running else 'inactive',
            'incidents_in_queue': queue_size,
            'predicted_incidents_next_hour': total_predicted_incidents,
            'active_hotspots': len(hotspots),
            'high_risk_areas': high_risk_areas,
            'total_risk_amount': total_risk_amount,
            'prediction_accuracy': accuracy,
            'model_confidence': calculate_model_confidence(hotspots),
            'trending_fraud_types': len(trends),
            'last_prediction_update': predictions['last_update'],
            'system_uptime': str(datetime.now() - real_time_processor.last_update) if real_time_processor.is_running else '0:00:00'
        }
        
        return jsonify({
            'success': True,
            'statistics': statistics,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@realtime_bp.route('/live-trends', methods=['GET'])
def get_live_trends():
    """Get real-time fraud trends"""
    try:
        predictions = real_time_processor.get_current_predictions()
        trends = predictions['predictions'].get('trends', {})
        
        # Format trends for dashboard
        trend_data = {
            'fraud_types': [],
            'growth_patterns': [],
            'risk_indicators': [],
            'geographical_trends': []
        }
        
        for fraud_type, data in trends.items():
            trend_data['fraud_types'].append({
                'type': fraud_type,
                'current_percentage': data['percentage'],
                'predicted_growth': data['growth_rate'],
                'status': data['status'],
                'risk_level': 'high' if data['percentage'] > 30 else 'medium'
            })
        
        # Add geographical trends from hotspots
        hotspots = predictions['predictions'].get('hotspots', [])
        for hotspot in hotspots:
            trend_data['geographical_trends'].append({
                'location': hotspot['city'],
                'trend': 'increasing' if hotspot['predicted_incidents'] > 2 else 'stable',
                'confidence': hotspot['confidence'],
                'predicted_change': f"+{hotspot['predicted_incidents']} incidents"
            })
        
        return jsonify({
            'success': True,
            'trends': trend_data,
            'last_update': predictions['last_update']
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@realtime_bp.route('/prediction-metrics', methods=['GET'])
def get_prediction_metrics():
    """Get detailed prediction model metrics"""
    try:
        predictions = real_time_processor.get_current_predictions()
        
        metrics = {
            'model_performance': {
                'accuracy': calculate_model_accuracy(),
                'precision': calculate_model_precision(),
                'recall': calculate_model_recall(),
                'f1_score': calculate_f1_score(),
                'last_training': datetime.now().isoformat()
            },
            'prediction_statistics': {
                'total_predictions_made': get_total_predictions(),
                'successful_predictions': get_successful_predictions(),
                'false_positives': get_false_positives(),
                'false_negatives': get_false_negatives()
            },
            'system_health': {
                'data_quality_score': calculate_data_quality(),
                'model_drift_detected': check_model_drift(),
                'recommendation': get_model_recommendation()
            }
        }
        
        return jsonify({
            'success': True,
            'metrics': metrics,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# Helper functions
def get_city_coordinates(city):
    """Get coordinates for city"""
    city_coords = {
        'Delhi': {'lat': 28.6139, 'lng': 77.2090},
        'Mumbai': {'lat': 19.0760, 'lng': 72.8777},
        'Bangalore': {'lat': 12.9716, 'lng': 77.5946},
        'Chennai': {'lat': 13.0827, 'lng': 80.2707},
        'Hyderabad': {'lat': 17.3850, 'lng': 78.4867},
        'Pune': {'lat': 18.5204, 'lng': 73.8567},
        'Gurgaon': {'lat': 28.4595, 'lng': 77.0266},
        'Noida': {'lat': 28.5355, 'lng': 77.3910}
    }
    return city_coords.get(city, {'lat': 28.6139, 'lng': 77.2090})

def get_severity_level(predicted_incidents):
    """Calculate severity based on predicted incidents"""
    if predicted_incidents >= 5:
        return 'critical'
    elif predicted_incidents >= 3:
        return 'high'
    elif predicted_incidents >= 1:
        return 'medium'
    else:
        return 'low'

def estimate_response_time(city):
    """Estimate response time for city"""
    response_times = {
        'Delhi': 15, 'Mumbai': 20, 'Bangalore': 18,
        'Chennai': 22, 'Hyderabad': 25, 'Pune': 20,
        'Gurgaon': 12, 'Noida': 15
    }
    return response_times.get(city, 30)

def calculate_required_units(predicted_incidents):
    """Calculate required police units"""
    return max(1, predicted_incidents // 2)

def calculate_model_confidence(hotspots):
    """Calculate overall model confidence"""
    if not hotspots:
        return 0.5
    
    avg_confidence = sum(h['confidence'] for h in hotspots) / len(hotspots)
    return round(avg_confidence, 3)

def calculate_model_accuracy():
    """Calculate model accuracy (simulated)"""
    return round(0.82 + np.random.uniform(-0.05, 0.05), 3)

def calculate_model_precision():
    """Calculate model precision (simulated)"""
    return round(0.78 + np.random.uniform(-0.03, 0.03), 3)

def calculate_model_recall():
    """Calculate model recall (simulated)"""
    return round(0.85 + np.random.uniform(-0.04, 0.04), 3)

def calculate_f1_score():
    """Calculate F1 score (simulated)"""
    precision = calculate_model_precision()
    recall = calculate_model_recall()
    return round(2 * (precision * recall) / (precision + recall), 3)

def get_total_predictions():
    """Get total predictions made (simulated)"""
    return np.random.randint(1500, 2000)

def get_successful_predictions():
    """Get successful predictions (simulated)"""
    total = get_total_predictions()
    return int(total * 0.85)

def get_false_positives():
    """Get false positives (simulated)"""
    total = get_total_predictions()
    return int(total * 0.12)

def get_false_negatives():
    """Get false negatives (simulated)"""
    total = get_total_predictions()
    return int(total * 0.08)

def calculate_data_quality():
    """Calculate data quality score (simulated)"""
    return round(0.88 + np.random.uniform(-0.05, 0.05), 3)

def check_model_drift():
    """Check for model drift (simulated)"""
    return np.random.choice([True, False], p=[0.1, 0.9])

def get_model_recommendation():
    """Get model recommendation"""
    drift = check_model_drift()
    accuracy = calculate_model_accuracy()
    
    if drift:
        return "Model retraining recommended due to data drift"
    elif accuracy < 0.8:
        return "Model performance below threshold - consider retraining"
    else:
        return "Model performing well - continue monitoring"